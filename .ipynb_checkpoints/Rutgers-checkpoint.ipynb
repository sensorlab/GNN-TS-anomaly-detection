{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f48aa90e-c821-4663-987f-00df7ea90d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mamba install tensorflow-gpu==2.11.0 -y -q\n",
    "!mamba install pytorch-cuda=11.6 -c pytorch -c conda-forge -c nvidia -y -q\n",
    "!mamba install -c conda-forge pyts==0.12.0 -y -q\n",
    "!pip install torch==1.13 torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu116 -q\n",
    "!pip install torch-scatter torch-sparse torch-cluster torch-spline-conv torch-geometric -f https://data.pyg.org/whl/torch-1.13.1+cu116.html -q\n",
    "!pip install ts2vg==1.2.1 -q\n",
    "!pip install pytorch_lightning==1.9.1 -q\n",
    "!pip install torchsummary==1.5.1 -q\n",
    "!pip install dvclive==2.0.2 -q\n",
    "!pip install pyedflib -q\n",
    "!pip install mne -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "859855bb-563e-4df2-9046-1df254885f4a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import warnings\n",
    "\n",
    "from pyts.image import MarkovTransitionField\n",
    "\n",
    "from ts2vg import NaturalVG\n",
    "from ts2vg import HorizontalVG\n",
    "\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "def get_Rutgers():\n",
    "    \"\"\"\n",
    "    Gets X, labels Y for graph clasification, and mask of Y for every sample for node classification, of a chosen Rutgers time series\n",
    "\n",
    "    Affected by:\n",
    "        Config[\"graph\"][\"len_type\"]\n",
    "        Config[\"graph\"][\"data_path\"]\n",
    "        Config[\"graph\"][\"folder_name\"]\n",
    "        Config[\"graph\"][\"properties_name\"]\n",
    "        Config[\"graph\"][\"mask_name\"]\n",
    "        \n",
    "    Returns:\n",
    "       _X: a 2D array containing the time steps of the rutgers dataset\n",
    "       mask: a 2D array containing the mask for node classification for the rutgers dataset\n",
    "       Y: a 1D array containing the mask for graph classification for the rutgers dataset\n",
    "    \"\"\"\n",
    "    # for the path containing time series, all with the same number of samples\n",
    "    if Config[\"graph\"][\"len_type\"] == \"un/cut\":\n",
    "        df = pd.read_csv(Config[\"graph\"][\"data_path\"] + Config[\"graph\"][\"folder_name\"])  \n",
    "        del df['Unnamed: 0']\n",
    "        df.index, df.columns = [range(df.index.size), range(df.columns.size)]\n",
    "        length_rss = int((df.columns.stop-2)/2)\n",
    "        \n",
    "        X = df.loc[:,df.columns[:length_rss]].to_numpy()\n",
    "        Y = df[length_rss+1].to_numpy(dtype=np.uint8)\n",
    "        mask = df.loc[:,df.columns[length_rss+2:]].to_numpy()\n",
    "        \n",
    "    # for the path containing time series, with diferent number of samples\n",
    "    elif Config[\"graph\"][\"len_type\"] == \"random\":\n",
    "        dataset_rss = np.load(Config[\"graph\"][\"data_path\"] + Config[\"graph\"][\"folder_name\"], allow_pickle=True)['arr_0']\n",
    "        dataset_properties = np.load(Config[\"graph\"][\"data_path\"] + Config[\"graph\"][\"properties_name\"], allow_pickle=True)['arr_0']\n",
    "        dataset_mask = np.load(Config[\"graph\"][\"data_path\"] + Config[\"graph\"][\"mask_name\"], allow_pickle=True)['arr_0']\n",
    "\n",
    "        for i in range(len(dataset_properties)):\n",
    "            dataset_properties[i,1] = int(dataset_properties[i,1])\n",
    "        \n",
    "        X = dataset_rss \n",
    "        mask = dataset_mask \n",
    "        Y = dataset_properties[:,2] \n",
    "        \n",
    "    return X, mask, Y\n",
    "\n",
    "def get_matrix(X_current):\n",
    "    \"\"\"\n",
    "    This function gets the adjacency matrix through either visibility, MTF, or dual VG graph\n",
    "    \n",
    "    Affected:\n",
    "        Config[\"graph\"][\"type\"]\n",
    "        Config[\"graph\"][\"VG\"][\"edge_type\"]\n",
    "        Config[\"graph\"][\"VG\"][\"edge_dir\"]\n",
    "        Config[\"graph\"][\"MTF\"][\"num_bins\"]\n",
    "        \n",
    "    Args:\n",
    "        X_current: a 1D array usually containing time series values\n",
    "    \n",
    "    Returns:\n",
    "        adj_mat: a list of adjacency matrices\n",
    "    \"\"\"\n",
    "    adj_mat = []\n",
    "    \n",
    "    # Check the graph type specified in the Config and perform the corresponding operations\n",
    "    if Config[\"graph\"][\"type\"] in (\"VG\", \"Dual_VG\"):\n",
    "        VGConfig = Config[\"graph\"][\"VG\"]\n",
    "        \n",
    "        # Create an instance of the visibility graph class based on the edge type specified\n",
    "        if VGConfig[\"edge_type\"] == \"natural\":\n",
    "            g = NaturalVG(weighted=VGConfig[\"distance\"])\n",
    "        elif VGConfig[\"edge_type\"] == \"horizontal\":\n",
    "            g = HorizontalVG(weighted=VGConfig[\"distance\"])\n",
    "\n",
    "        # Build the visibility graph using the provided time series\n",
    "        g.build(X_current)\n",
    "\n",
    "        adj_mat_vis = np.zeros([len(X_current), len(X_current)], dtype='float')\n",
    "        \n",
    "        # Iterate over the edges of the visibility graph and assign weights to the corresponding positions in the adjacency matrix\n",
    "        for x, y, q in g.edges:\n",
    "            adj_mat_vis[x, y] = q\n",
    "            if VGConfig[\"edge_dir\"] == \"undirected\":\n",
    "                adj_mat_vis[y, x] = q\n",
    "        \n",
    "        adj_mat.append(adj_mat_vis)\n",
    "        \n",
    "    elif Config[\"graph\"][\"type\"] == \"MTF\":\n",
    "        n_bins = Config[\"graph\"][\"MTF\"][\"num_bins\"]\n",
    "        if n_bins == \"auto\":\n",
    "            n_bins = len(X_current)\n",
    "        #is used to ignore some warnings as  the instance of MTF is being computed\n",
    "        warnings.filterwarnings(\"ignore\")\n",
    "        \n",
    "        # Create and compute an instance of the Markov Transition Field class\n",
    "        MTF = MarkovTransitionField(n_bins=n_bins)\n",
    "        X_gaf_MTF_temp = MTF.fit_transform(X_current.reshape(1, -1))\n",
    "        adj_mat.append(X_gaf_MTF_temp[0])\n",
    "    \n",
    "    return adj_mat\n",
    "    \n",
    "def adjToEdgidx(adj_mat):\n",
    "    \"\"\"\n",
    "    This function creates edge indexes and weights for a given matrix\n",
    "    \n",
    "    Args:\n",
    "        adj_mat: a 2D array\n",
    "\n",
    "    Returns:\n",
    "        edge_index: a 2D torch array that indicates the connected values\n",
    "        edge_weight: a 1D array of weights that represent the absolute distance between connected nodes or values in the time series\n",
    "    \"\"\"\n",
    "    edge_index = torch.from_numpy(adj_mat[0]).nonzero().t().contiguous()\n",
    "    row, col = edge_index\n",
    "    edge_weight = adj_mat[0][row, col]\n",
    "    return edge_index, edge_weight\n",
    "\n",
    "def adjToEdgidx_Dual_VG(X_current):\n",
    "    \"\"\"\n",
    "    Creates a dual visibility graph by first creating a directed VG from one side and then flipping and running the get_matrix function again.\n",
    "    By doing this, we join these two graphs and obtain a dual VG.\n",
    "\n",
    "    Args:\n",
    "        X_current: 1D array usually containing time series values\n",
    "\n",
    "    Returns:\n",
    "        edge_index: 2D torch array that defines the connected values\n",
    "        edge_weight: 2D array of weights that represent the absolute distance between every node or value in the time series\n",
    "    \"\"\"\n",
    "    pos_adj_mat_vis = get_matrix(X_current)[0]\n",
    "    neg_adj_mat_vis = get_matrix(-X_current)[0]\n",
    "    edge_index = torch.from_numpy(pos_adj_mat_vis + neg_adj_mat_vis).nonzero().t().contiguous()\n",
    "\n",
    "    # Join two edge_weight arrays\n",
    "    row, col = edge_index\n",
    "    edge_weight = np.zeros([len(row), 2], dtype='float')\n",
    "    edge_weight[:, 0] = pos_adj_mat_vis[row, col]\n",
    "    edge_weight[:, 1] = neg_adj_mat_vis[row, col]\n",
    "\n",
    "    return edge_index, edge_weight\n",
    "    \n",
    "def create_graph(output, X, mask, Y):\n",
    "    \"\"\"\n",
    "    Creates a graph in the torch geometric Data format, containing the node values x, mask values for training, testing, and validation, edge indexes, and edge attributes.\n",
    "\n",
    "    Affected by:\n",
    "        Config[\"graph\"][\"type\"]\n",
    "        Config[\"graph\"][\"classif\"]\n",
    "    \n",
    "    Args:\n",
    "        output: Dataset of multiple graphs (optional). New graph will be appended to this dataset.\n",
    "        X: Node values (integer).\n",
    "        mask: 1D array representing the mask.\n",
    "\n",
    "    Returns:\n",
    "        output: Updated dataset of multiple or singular graph.\n",
    "    \"\"\"\n",
    "    if Config[\"graph\"][\"type\"] in (\"VG\", \"MTF\"):\n",
    "        edge_index, edge_weight = adjToEdgidx(get_matrix(X))\n",
    "    elif Config[\"graph\"][\"type\"] == \"Dual_VG\":\n",
    "        edge_index, edge_weight = adjToEdgidx_Dual_VG(X)\n",
    "    \n",
    "    \n",
    "    \n",
    "    x = torch.unsqueeze(torch.tensor(X, dtype=torch.double), 1).clone().detach()\n",
    "    edge_index = edge_index.clone().detach().to(torch.int64)\n",
    "    edge_attr = torch.unsqueeze(torch.tensor(edge_weight, dtype=torch.double), 1).clone().detach()\n",
    "    \n",
    "    if Config[\"graph\"][\"classif\"] == \"graph\": # for graph classification\n",
    "        y = torch.tensor(Y, dtype=torch.long)\n",
    "    elif Config[\"graph\"][\"classif\"] == \"node\":# for node classification \n",
    "        y = torch.unsqueeze(torch.tensor(mask, dtype=torch.double),1)\n",
    "\n",
    "\n",
    "    output.append(Data(x=x, edge_index=edge_index, edge_attr=edge_attr, y=y))\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "53783ffe-df78-494f-a477-4f2ed4aa34e9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.utils import class_weight\n",
    "def Rutgers_graph():\n",
    "    \"\"\"\n",
    "    Performs a pipeline of operations to process the Rutgers dataset for a given utility.\n",
    "\n",
    "    Affected by:\n",
    "        Config[\"graph\"]\n",
    "\n",
    "    Returns:\n",
    "        output: A list containing the processed graph data.\n",
    "        class_weights: Torch tensor containing the computed class weights.\n",
    "    \"\"\"\n",
    "    # creates X, mask of lables and Y as a graph lable\n",
    "    X, mask, Y = get_Rutgers()\n",
    "    \n",
    "    # here graphs are appended to the dataset\n",
    "    dataset = []\n",
    "    for i in range(len(X)):\n",
    "        dataset = create_graph(dataset, X[i], mask[i],Y[i])\n",
    "        \n",
    "    # join all lables into a 1D array\n",
    "    all_x = np.reshape(np.concatenate([obj.y for obj in dataset]), (-1,))\n",
    "    \n",
    "    class_weights = torch.tensor(class_weight.compute_class_weight(class_weight='balanced',\n",
    "                                                                    classes=np.unique(all_x),\n",
    "                                                                    y=all_x))\n",
    "    if Config[\"graph\"][\"classif\"] == \"node\":\n",
    "        class_weights =torch.tensor([class_weights[1]/class_weights[0]])\n",
    "\n",
    "    return dataset, class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a64020ba-1f96-47a3-a5e7-70e9d74d55d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from pytorch_lightning.callbacks import EarlyStopping\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "\n",
    "from dvclive.lightning import DVCLiveLogger\n",
    "\n",
    "from torch.nn import Sequential, BatchNorm1d, ReLU\n",
    "from torch.nn import Linear, CrossEntropyLoss, BCEWithLogitsLoss\n",
    "\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.nn import GINEConv, GATConv\n",
    "from torch_geometric.nn import global_max_pool\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from torch import nn\n",
    "\n",
    "\"\"\"\n",
    "This is the definition of a model arhitecture created for graph classification using GINEConv layers\n",
    "\"\"\" \n",
    "class GINE(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        if Config[\"graph\"][\"type\"] in (\"MTF\", \"VG\"):\n",
    "            edge_dim = 1\n",
    "        elif Config[\"graph\"][\"type\"] in (\"dual_VG\"):\n",
    "            edge_dim = 2\n",
    "\n",
    "        dim_h = 32\n",
    "        # Define GINEConv and Linear layers\n",
    "        self.conv1 = GINEConv(\n",
    "            Sequential(Linear(dim_h, dim_h),\n",
    "                       BatchNorm1d(dim_h), ReLU(),\n",
    "                       Linear(dim_h, dim_h), ReLU()), edge_dim=edge_dim)\n",
    "\n",
    "        self.conv2 = GINEConv(\n",
    "            Sequential(Linear(dim_h, dim_h), BatchNorm1d(dim_h), ReLU(),\n",
    "                       Linear(dim_h, dim_h), ReLU()), edge_dim=edge_dim)\n",
    "\n",
    "        self.conv3 = GINEConv(\n",
    "            Sequential(Linear(dim_h, dim_h), BatchNorm1d(dim_h), ReLU(),\n",
    "                       Linear(dim_h, dim_h), ReLU()), edge_dim=edge_dim)\n",
    "\n",
    "        self.conv4 = GINEConv(\n",
    "            Sequential(Linear(dim_h, dim_h), BatchNorm1d(dim_h), ReLU(),\n",
    "                       Linear(dim_h, dim_h), ReLU()), edge_dim=edge_dim)\n",
    "\n",
    "        self.conv5 = GINEConv(\n",
    "            Sequential(Linear(dim_h, dim_h), BatchNorm1d(dim_h), ReLU(),\n",
    "                       Linear(dim_h, dim_h), ReLU()), edge_dim=edge_dim)\n",
    "\n",
    "\n",
    "        self.lin1 = Linear(dim_h*5, dim_h*5)\n",
    "        self.lin2 = Linear(dim_h*5, 5)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index, edge_weight, batch = data.x, data.edge_index, data.edge_attr, data.batch\n",
    "\n",
    "        # Node embeddings \n",
    "        h1 = self.conv1(x, edge_index, edge_attr=edge_weight)\n",
    "        h2 = self.conv2(h1, edge_index, edge_attr=edge_weight)\n",
    "        h3 = self.conv3(h2, edge_index, edge_attr=edge_weight)\n",
    "        h4 = self.conv4(h3, edge_index, edge_attr=edge_weight)\n",
    "        h5 = self.conv5(h4, edge_index, edge_attr=edge_weight)\n",
    "\n",
    "        # Graph-level readout\n",
    "        h1 = global_max_pool(h1, batch)\n",
    "        h2 = global_max_pool(h2, batch)\n",
    "        h3 = global_max_pool(h3, batch)\n",
    "        h4 = global_max_pool(h4, batch)\n",
    "        h5 = global_max_pool(h5, batch)\n",
    "\n",
    "        # Concatenate graph embeddings\n",
    "        h = torch.cat((h1, h2, h3, h4, h5), dim=1)\n",
    "\n",
    "        # Classifier\n",
    "        h = self.lin1(h)\n",
    "        h = h.relu()\n",
    "        h = F.dropout(h, p=0.5, training=self.training)\n",
    "        h = self.lin2(h)\n",
    "\n",
    "        return h\n",
    "\n",
    "\"\"\"\n",
    "This is the definition of a model arhitecture created for node classification using GATConv and Linear layers\n",
    "\"\"\" \n",
    "class GAT(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Define GATConv and Linear layers\n",
    "        self.conv1 = GATConv(1, 32, heads=4)\n",
    "        self.lin1 = torch.nn.Linear(1, 4 * 32)\n",
    "        self.conv2 = GATConv(4 * 32, 32, heads=4)\n",
    "        self.lin2 = torch.nn.Linear(4 * 32, 4 * 32)\n",
    "        self.conv3 = GATConv(4 * 32, 1, heads=6,concat=False)\n",
    "        self.lin3 = torch.nn.Linear(4 * 32, 1)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index, edge_weight = data.x, data.edge_index, data.edge_attr\n",
    "        # Process input data through convolutional and linear layers\n",
    "        x = F.elu(self.conv1(x, edge_index) + self.lin1(x))\n",
    "        x = F.elu(self.conv2(x, edge_index) + self.lin2(x))\n",
    "        x = self.conv3(x, edge_index) + self.lin3(x)\n",
    "        return x\n",
    "    \n",
    "    \n",
    "\"\"\"\n",
    "class NGClassifier is a Pytorch Lightning class that is used to train, validate and test a model arhitecture for graph or node classificaiton\n",
    "\"\"\" \n",
    "class NGClassifier(pl.LightningModule):\n",
    "    def __init__(self, class_weights, model,Config):\n",
    "        super().__init__()\n",
    "        self.class_weights = class_weights\n",
    "        self.model = model\n",
    "        self.Config = Config\n",
    "        \n",
    "    def configure_optimizers(self):\n",
    "        \"\"\"\n",
    "        Configures the optimizer for training the model.\n",
    "        \n",
    "        Affected by:\n",
    "            Config[\"graph\"][\"learning_rate\"]\n",
    "        \n",
    "        Returns:\n",
    "            optimizer: The configured optimizer.\n",
    "        \"\"\"\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=self.Config[\"model\"][\"learning_rate\"], weight_decay=5e-4)\n",
    "        return optimizer\n",
    "    \n",
    "    def acc_pred(self, out, y):\n",
    "        \"\"\"\n",
    "        Calculates the accuracy and predicted labels that the trained model has generated.\n",
    "\n",
    "        Affected by:\n",
    "            Config[\"graph\"][\"classif\"]\n",
    "\n",
    "        Args:\n",
    "            out: Output values from a trained model.\n",
    "            y: True labels.\n",
    "\n",
    "        Returns:\n",
    "            accuracy: Accuracy of the model's predictions.\n",
    "            pred: Predicted labels.\n",
    "        \"\"\"\n",
    "        if self.Config[\"graph\"][\"classif\"] == \"graph\":\n",
    "            pred = out.argmax(-1)\n",
    "            accuracy = (pred == y).sum() / pred.shape[0]\n",
    "            \n",
    "        elif self.Config[\"graph\"][\"classif\"] == \"node\":\n",
    "            preds = []\n",
    "            preds.append((out > 0).float().cpu())     \n",
    "            pred = torch.cat(preds, dim=0)\n",
    "            accuracy = (pred == y.cpu()).sum() / pred.shape[0]\n",
    "        \n",
    "        return accuracy, pred\n",
    "    \n",
    "    def loss_function_selection(self):\n",
    "        \"\"\"\n",
    "        Choses a loss function depending on what type of classification is happening (graph or node classification)\n",
    "\n",
    "        Affected by:\n",
    "            Config[\"graph\"][\"classif\"]\n",
    "\n",
    "        Returns:\n",
    "            a loss funciton \n",
    "        \"\"\"\n",
    "        if self.Config[\"graph\"][\"classif\"] == \"graph\":\n",
    "            return CrossEntropyLoss(weight=self.class_weights).to(device)\n",
    "        elif self.Config[\"graph\"][\"classif\"] == \"node\":\n",
    "            return BCEWithLogitsLoss(weight=self.class_weights).to(device)\n",
    "            \n",
    "    def training_step(self, train_batch, batch_idx):\n",
    "        \"\"\"\n",
    "        Performs a single training step on the given batch of train data.\n",
    "\n",
    "        Args:\n",
    "            train_batch: Input data for the training step.\n",
    "            batch_idx: Index of the current batch.\n",
    "\n",
    "        Returns:\n",
    "            train_loss: Loss value for the training step.\n",
    "        \"\"\"\n",
    "        out = self.model(train_batch)\n",
    "        loss_function = self.loss_function_selection()\n",
    "        train_loss = loss_function(out, train_batch.y)\n",
    "        \n",
    "        return train_loss\n",
    "    \n",
    "    def validation_step(self, val_batch, batch_idx):\n",
    "        \"\"\"\n",
    "        Performs a single validation step on the given batch of validation data. It logs val_loss and accuracy for early stoping and saving the best trained models\n",
    "        \n",
    "        Args:\n",
    "            val_batch: Test data for the current batch.\n",
    "            batch_idx: Index of the current batch.\n",
    "        \"\"\"\n",
    "        out = self.model(val_batch)\n",
    "        loss_function = self.loss_function_selection()\n",
    "        val_loss = loss_function(out, val_batch.y)\n",
    "        \n",
    "        accuracy, pred = self.acc_pred(out, val_batch.y)\n",
    "        \n",
    "        self.log(\"val_loss\", val_loss)\n",
    "        self.log(\"val_acc\", accuracy)        \n",
    "    \n",
    "    def test_step(self, test_batch, batch_idx):\n",
    "        \"\"\"\n",
    "        Performs a forward pass on the model to obtain predictions for the test data. It logs accuracy, and collects the true labels and predicted labels for later evaluation.\n",
    "\n",
    "        Args:\n",
    "            test_batch: Test data for the current batch.\n",
    "            batch_idx: Index of the current batch.\n",
    "\n",
    "        Returns:\n",
    "            pred: Predicted labels for the test data.\n",
    "            y: True labels for the test data.\n",
    "        \"\"\"\n",
    "        out = self.model(test_batch)\n",
    "        loss_function = self.loss_function_selection()\n",
    "        test_loss = loss_function(out, test_batch.y)\n",
    "        \n",
    "        accuracy, pred = self.acc_pred(out, test_batch.y)\n",
    "        \n",
    "        self.log(\"test_acc\", accuracy)\n",
    "        return pred, test_batch.y\n",
    "\n",
    "        \n",
    "    def test_epoch_end(self, outputs):\n",
    "        \"\"\"\n",
    "        This function receives accumulated predicted and true labels from the test_step and uses them on the confusion matrix and classification report that are than printed.\n",
    "        \n",
    "        Args:\n",
    "            outputs: Contains an array of predicted and an array of true lables\n",
    "\n",
    "        \"\"\"\n",
    "        global true_array, true_array\n",
    "        true_array=[outputs[i][1].cpu().numpy() for i in range(len(outputs))]\n",
    "        pred_array = [outputs[i][0].cpu().numpy() for i in range(len(outputs))]    \n",
    "        pred_array = np.array(pred_array).reshape(-1, 1)\n",
    "        true_array = np.array(true_array).reshape(-1, 1)\n",
    "        print(confusion_matrix(true_array, pred_array))\n",
    "        print(classification_report(true_array, pred_array))\n",
    "        \n",
    "        \n",
    "def main():\n",
    "\n",
    "    \"\"\"\n",
    "    Main function for training.\n",
    "    \n",
    "    Affected by:\n",
    "        Config[\"graph\"][\"classif\"]\n",
    "        Config[\"model\"]\n",
    "    \"\"\"\n",
    "    \n",
    "    global device\n",
    "    # initiate callback functions, DVC, Seed and device\n",
    "    early_stop = EarlyStopping(monitor='val_acc',patience=Config[\"model\"][\"patience\"], strict=False,verbose=False, mode='max')\n",
    "    val_checkpoint_best_loss = ModelCheckpoint(filename=\"best_loss\", monitor = \"val_loss\", mode=\"max\")\n",
    "    logger = DVCLiveLogger() # the bonus of using DVCLiveLogger() is that you can visualise the validation accuracy live in dvclive/report.html\n",
    "    \n",
    "    torch.manual_seed(Config[\"model\"][\"SEED\"])\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    \n",
    "    # creates dataset containing graphs and the overall class_weights\n",
    "    output, class_weights = Rutgers_graph() \n",
    "\n",
    "    # sets the train, validation and test sizes and atributes a number of time series coresponding to those sizes to every DataLoader\n",
    "    train_size = int(Config[\"model\"][\"train/val/test\"][\"train\"] * len(output))\n",
    "    val_size = int(Config[\"model\"][\"train/val/test\"][\"val\"]*len(output))\n",
    "    test_size = len(output) - (val_size + train_size) \n",
    "    train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(output, [train_size, val_size, test_size])\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=Config[\"model\"][\"batch_size\"], shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=int(Config[\"model\"][\"batch_size\"]/2), shuffle=False)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "    # initializes graph or node model\n",
    "    if Config[\"graph\"][\"classif\"] == \"graph\":\n",
    "        model = NGClassifier(class_weights,GINE(),Config).double() #GINE is for graph classification\n",
    "    elif Config[\"graph\"][\"classif\"] == \"node\":\n",
    "        model = NGClassifier(class_weights, GAT(),Config).double() #GAT is for node classification          \n",
    "    \n",
    "    #traines the model arhitecture\n",
    "    trainer = pl.Trainer(logger=logger, max_epochs = Config[\"model\"][\"range_epoch\"], callbacks=[val_checkpoint_best_loss,early_stop],accelerator='gpu',devices=1)\n",
    "    trainer.fit(model, train_loader, val_loader)\n",
    "    \n",
    "    #tests the model arhitecture and prints the results\n",
    "    tester = pl.Trainer(accelerator='gpu',devices=1)\n",
    "    tester.test(model, test_loader)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b80517e4-8562-4163-8ec1-5db7dd2cca92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def report(csv_name,true_array, pred_array):\n",
    "    \"\"\"\n",
    "    Generates a classification report based on the true and predicted arrays for a given utility.\n",
    "\n",
    "    Args:\n",
    "        csv_name: Name of the .csv file.\n",
    "        true_array: Array of true labels.\n",
    "        pred_array: Array of predicted labels.\n",
    "\n",
    "    Returns:\n",
    "        Saves the report as a CSV file.\n",
    "    \"\"\"\n",
    "    print(csv_name)\n",
    "    report = classification_report(true_array, pred_array, output_dict=True)\n",
    "    df = pd.DataFrame(report).transpose()\n",
    "    file_name = 'results_rutgers_VG_8-2_'+str(Config[\"model\"][\"SEED\"])+'_Without_linear/'+csv_name\n",
    "    \n",
    "    # Create the directory if it doesn't exist\n",
    "    directory = os.path.dirname(file_name)\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "    \n",
    "    df.to_csv(file_name +\".csv\")\n",
    "    shutil.make_archive(file_name, 'zip', file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6188f058-2078-43e6-9467-ee23f2b351c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This list contains configurations for generating and training a graph from a Rutgers time series\n",
    "\"\"\"\n",
    "Config = {\n",
    "    \"graph\": {\n",
    "        \"data_path\" : \"datasets/Rutgers/\", # path to datasets\n",
    "        \"folder_name\" : \"dataset_uncut.csv\", #\"dataset_uncut.csv\", \"dataset_cut.csv\", \"dataset_rss.npz\", paths used for cut/uncut/random dataset\n",
    "        \"properties_name\" : \"dataset_properties.npz\",  # path to properties used for random \n",
    "        \"mask_name\" : \"dataset_mask.npz\", # path to mask dataset used for random\n",
    "        \"classif\": \"node\",  # Type of classification (node or graph)\n",
    "        \"len_type\" : \"un/cut\", #\"un/cut\", \"random\", the shape of data used in later paths \n",
    "        \"type\": \"VG\",  # Type of graph (MTF, VG, Dual_VG)\n",
    "        \"MTF\": {\n",
    "            \"num_bins\": \"auto\"  # Number of bins for MTF graph (integer or \"auto\")\n",
    "        },\n",
    "        \"VG\": {\n",
    "            \"edge_type\": \"natural\",  # Type of edge calculation for VG graph (natural or horizontal)\n",
    "            \"distance\": 'distance',  # Type of distance metric for VG graph\n",
    "                                    # (slope, abs_slope, distance, h_distance, v_distance, abs_v_distance)\n",
    "            \"edge_dir\": \"directed\"  # Directionality of edges in VG graph (undirected or directed)\n",
    "        }\n",
    "    },\n",
    "    \n",
    "    \"model\": {\n",
    "        \"SEED\": 280,  # Random seed for reproducibility\n",
    "        \"learning_rate\": 0.005,  # Learning rate for training\n",
    "        \"batch_size\": 64,  # Batch size for training\n",
    "        \"range_epoch\": 200,  # Number of training epochs\n",
    "        \"save_file\": \"test_test\",  # File name for saving trained model\n",
    "        \"name_of_save\": \"test_u-time\",  # Name of the save (e.g., checkpoint name)\n",
    "        \"patience\": 500,  # Patience for early stopping\n",
    "        \"train/val/test\": {\n",
    "            \"train\": 0.8,  # Percentage of data used for training\n",
    "            \"val\": 0.04,  # Percentage of data used for validation\n",
    "            \"test\": 0.16  # Percentage of data used for testing\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4902429-c32a-47dc-a7d8-b61a9c7f7c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This for loop runs the main function for graph generation, training and saving the testing results into a csv file.\n",
    "The trained model can be found in DvcLiveLogger/dvclive_run/checkpoints.\n",
    "\"\"\"\n",
    "#Most common Config parameters\n",
    "Config[\"graph\"][\"classif\"] = \"node\"\n",
    "Config[\"graph\"][\"type\"] = \"VG\"\n",
    "Config[\"model\"][\"SEED\"] = 280\n",
    "\n",
    "#For generating, training and testing the graph\n",
    "main()\n",
    "# Generate a classification report for the utility\n",
    "# report(get_versions_TSSB()[utility][:-4],true_array, pred_array,2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
